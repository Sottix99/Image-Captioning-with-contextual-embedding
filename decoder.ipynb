{"cells":[{"cell_type":"markdown","id":"30bcf562","metadata":{"id":"30bcf562"},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":null,"id":"iVu57xNUKR7L","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20630,"status":"ok","timestamp":1670963157056,"user":{"displayName":"francesco sciarra","userId":"17926562299953983564"},"user_tz":-60},"id":"iVu57xNUKR7L","outputId":"d35f0ad1-cf6b-41fe-935d-23a854b88b96"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"6654e14e","metadata":{"id":"6654e14e"},"outputs":[],"source":["import datasets\n","import transformers\n","import pandas as pd\n","import torch\n","from torch.utils.data.dataset import Dataset\n","from pathlib import Path\n","\n","from tokenizers import ByteLevelBPETokenizer\n","\n","from transformers import RobertaConfig\n","from transformers import RobertaForMaskedLM # RobertaLM for learning\n","from transformers import RobertaTokenizerFast # After training tokenizern we will wrap it so it can be used by Roberta model\n","\n","from transformers import Seq2SeqTrainer\n","from transformers import Seq2SeqTrainingArguments\n","from transformers import Trainer, TrainingArguments"]},{"cell_type":"markdown","id":"2b2f1a73","metadata":{"id":"2b2f1a73"},"source":["# Parameters for Training"]},{"cell_type":"code","execution_count":null,"id":"a0af58b0","metadata":{"id":"a0af58b0"},"outputs":[],"source":["TRAIN_BATCH_SIZE = 64   # input batch size for training (default: 64)\n","VALID_BATCH_SIZE = 256   # input batch size for testing (default: 1000)\n","VAL_EPOCHS = 1 \n","LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n","MAX_LEN = 128           # Max length for product description\n","SUMMARY_LEN = 20         # Max length for product names\n","\n","TRAIN_EPOCHS = 20       # number of epochs to train (default: 10)\n","WEIGHT_DECAY = 0.01\n","MAX_LEN = 128\n","SUMMARY_LEN = 20   # Maximum length of caption generated by the model"]},{"cell_type":"code","execution_count":null,"id":"E0R5PiyXLIjT","metadata":{"id":"E0R5PiyXLIjT"},"outputs":[],"source":["caption_path = \"data.json\""]},{"cell_type":"markdown","id":"83fe6145","metadata":{"id":"83fe6145"},"source":["# Preparing the Dataset"]},{"cell_type":"code","execution_count":null,"id":"a581f10c","metadata":{"id":"a581f10c"},"outputs":[],"source":["import os\n","import json\n","import pandas as pd\n","\n","\n","with open(caption_path, 'r') as openfile:\n","    json_object = json.load(openfile)\n","\n","images_caption_dict = dict(json_object)\n","images_path = \"Flicker8k_Dataset/\"\n","images = list(images_caption_dict.keys())\n","\n","for image_path in images:\n","    if image_path.endswith('jpg'):\n","        new = images_path + image_path.split('/')[-1]\n","        images_caption_dict[new] = images_caption_dict.pop(image_path)\n","    else:\n","        images_caption_dict.pop(image_path)"]},{"cell_type":"code","execution_count":null,"id":"203d74b5","metadata":{"id":"203d74b5"},"outputs":[],"source":["\n","\n","df = pd.DataFrame([])\n","captions = []\n","images = []\n","for image in list(images_caption_dict.keys()):\n","    caption = images_caption_dict[image]\n","    for capt in caption:\n","        captions.append(capt.replace('<s> ','').replace('  <e>','').strip())\n","        images.append(image)\n","        \n","df['images'] = images\n","df['captions'] = captions"]},{"cell_type":"markdown","id":"674ab7d3","metadata":{"id":"674ab7d3"},"source":["# ROBERTA\n","### Training the Decoder Model for Language Understanding and build Vocabulary"]},{"cell_type":"markdown","id":"0b12a0c9","metadata":{"id":"0b12a0c9"},"source":["### Tokenizer\n","#### Converting captions in to .txt file for training of the tokenizer"]},{"cell_type":"code","execution_count":null,"id":"e956c1c0","metadata":{"id":"e956c1c0"},"outputs":[],"source":["# Store values in a dataframe column (Series object) to files, one file per record\n","def column_to_files(column, prefix, txt_files_dir = \"./text_split\"):\n","    # The prefix is a unique ID to avoid to overwrite a text file\n","    i=prefix\n","    #For every value in the df, with just one column\n","    for row in column.to_list():\n","      # Create the filename using the prefix ID\n","        file_name = os.path.join(txt_files_dir, str(i)+'.txt')\n","        try:\n","            # Create the file and write the column text to it\n","            f = open(file_name, 'wb')\n","            f.write(row.encode('utf-8'))\n","            f.close()\n","        except Exception as e:  #catch exceptions(for eg. empty rows)\n","            print(row, e) \n","        i+=1\n","    # Return the last ID\n","    return i\n","\n","data = df[\"captions\"]\n","data = data.replace(\"\\n\",\" \")\n","# Set the ID to 0\n","prefix=0\n","# Create a file for every description value\n","prefix = column_to_files(data, prefix)\n","# Print the last ID"]},{"cell_type":"markdown","id":"5d55eaff","metadata":{"id":"5d55eaff"},"source":["#### Training tokenizer"]},{"cell_type":"code","execution_count":null,"id":"23b01bc2","metadata":{"id":"23b01bc2","outputId":"896392b9-dbbf-4ce4-fd68-e002ee4be4b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wall time: 2min 54s\n"]}],"source":["%%time \n","paths = [str(x) for x in Path(\".\").glob(\"text_split/*.txt\")]\n","\n","# Initialize a tokenizer\n","tokenizer = ByteLevelBPETokenizer(lowercase=True)\n","\n","# Customize training\n","tokenizer.train(files=paths, vocab_size=10000, min_frequency=2,\n","                show_progress=True,\n","                special_tokens=[\n","                                \"<s>\",\n","                                \"<pad>\",\n","                                \"<e>\",\n","                                \"<unk>\",\n","                                \"<mask>\",\n","])"]},{"cell_type":"markdown","id":"2599851c","metadata":{"id":"2599851c"},"source":["#### Save Tokenizer"]},{"cell_type":"code","execution_count":null,"id":"463597cb","metadata":{"id":"463597cb","outputId":"11055fa5-6474-471c-ef87-f6a36b441ce1"},"outputs":[{"data":{"text/plain":["['Byte_tokenizer_finetuned\\\\vocab.json',\n"," 'Byte_tokenizer_finetuned\\\\merges.txt']"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.save_model('Byte_tokenizer_finetuned')"]},{"cell_type":"markdown","id":"62c98310","metadata":{"id":"62c98310"},"source":["## Decoder\n","#### Intialization & Training"]},{"cell_type":"code","execution_count":null,"id":"617c6d6f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3999,"status":"ok","timestamp":1670963562265,"user":{"displayName":"francesco sciarra","userId":"17926562299953983564"},"user_tz":-60},"id":"617c6d6f","outputId":"10e1408e-7264-4143-908a-ffa118cd94b9"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading weights file pytorch_model.bin from cache at C:\\Users\\giaco/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\\pytorch_model.bin\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing RobertaForMaskedLM: ['bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.4.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'cls.seq_relationship.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'cls.predictions.decoder.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.bias', 'cls.seq_relationship.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.9.intermediate.dense.bias', 'cls.predictions.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.10.intermediate.dense.bias']\n","- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['encoder.layer.4.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'lm_head.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'lm_head.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.1.attention.self.key.bias', 'lm_head.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'lm_head.layer_norm.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.1.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'lm_head.layer_norm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.weight', 'embeddings.word_embeddings.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","loading file vocab.json\n","loading file merges.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n"]},{"name":"stdout","output_type":"stream","text":["Num parameters:  51206416\n"]}],"source":["\n","config = RobertaConfig(\n","    vocab_size=10000,\n","    max_position_embeddings=514,\n","    num_attention_heads=12,\n","    num_hidden_layers=6,\n","    type_vocab_size=1,\n","    #hidden_dropout_prob = 0.5,\n","    #attention_probs_dropout_prob = 0.5\n",")\n","model = RobertaForMaskedLM.from_pretrained(\"bert-base-uncased\",config=config)\n","# Create the tokenizer from a trained one\n","tokenizer = RobertaTokenizerFast.from_pretrained('Byte_tokenizer_finetuned', max_len=MAX_LEN)"]},{"cell_type":"code","execution_count":null,"id":"c8ae1ac7","metadata":{"id":"c8ae1ac7"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, df, tokenizer):\n","        self.examples = []\n","        for example in df.values:\n","            x=tokenizer.encode_plus(example, max_length = MAX_LEN, truncation=True, padding=True)\n","            self.examples += [x.input_ids]\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, i):\n","        return torch.tensor(self.examples[i])"]},{"cell_type":"code","execution_count":null,"id":"8289594c","metadata":{"id":"8289594c"},"outputs":[],"source":["# Create the train and evaluation dataset\n","train_dataset = CustomDataset(df['captions'][:38000], tokenizer)\n","eval_dataset = CustomDataset(df['captions'][38000:], tokenizer)"]},{"cell_type":"markdown","id":"20893ec7","metadata":{"id":"20893ec7"},"source":["#### Batching Data"]},{"cell_type":"code","execution_count":null,"id":"a4f6f890","metadata":{"id":"a4f6f890"},"outputs":[],"source":["from transformers import DataCollatorForLanguageModeling\n","\n","# Define the Data Collator\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",")"]},{"cell_type":"markdown","id":"b18e9ba3","metadata":{"id":"b18e9ba3"},"source":["## Training the Decoder"]},{"cell_type":"code","execution_count":null,"id":"ae2f832b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1670963582689,"user":{"displayName":"francesco sciarra","userId":"17926562299953983564"},"user_tz":-60},"id":"ae2f832b","outputId":"4e87d020-3041-435c-d9c4-737953a2dfcf"},"outputs":[{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}],"source":["model_folder = \"RobertaMLM_finetuned\"\n","# Define the training arguments\n","training_args = TrainingArguments(\n","    output_dir=model_folder,\n","    overwrite_output_dir=True,\n","    evaluation_strategy = 'epoch',\n","    num_train_epochs=TRAIN_EPOCHS,\n","    learning_rate=LEARNING_RATE,\n","    weight_decay=WEIGHT_DECAY,\n","    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n","    per_device_eval_batch_size=VALID_BATCH_SIZE,\n","    save_steps=8192,\n","    save_total_limit=1\n",")\n","# Create the trainer for our model\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset\n",")"]},{"cell_type":"code","execution_count":null,"id":"cc692d01","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":557},"executionInfo":{"elapsed":10969917,"status":"ok","timestamp":1670974579624,"user":{"displayName":"francesco sciarra","userId":"17926562299953983564"},"user_tz":-60},"id":"cc692d01","outputId":"ece9d311-8fee-473a-9d3e-70759f120217","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\giaco\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 38000\n","  Num Epochs = 20\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 11880\n","  Number of trainable parameters = 51206416\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='11880' max='11880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [11880/11880 22:29, Epoch 20/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>5.077800</td>\n","      <td>4.000446</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>3.870700</td>\n","      <td>3.391426</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>3.395000</td>\n","      <td>3.165023</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>3.125700</td>\n","      <td>2.840739</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>2.948700</td>\n","      <td>2.747571</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>2.683600</td>\n","      <td>2.641423</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>2.571600</td>\n","      <td>2.600869</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>2.527900</td>\n","      <td>2.544489</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>2.472300</td>\n","      <td>2.491435</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>2.369100</td>\n","      <td>2.424572</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>2.289000</td>\n","      <td>2.381561</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>2.236600</td>\n","      <td>2.341741</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>2.179300</td>\n","      <td>2.310194</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>2.169000</td>\n","      <td>2.299402</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>2.120900</td>\n","      <td>2.306943</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>2.070100</td>\n","      <td>2.218038</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>2.033500</td>\n","      <td>2.331001</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>2.013300</td>\n","      <td>2.201564</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>1.989000</td>\n","      <td>2.292218</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.990400</td>\n","      <td>2.233483</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","Saving model checkpoint to RobertaMLM_finetuned\\checkpoint-8192\n","Configuration saved in RobertaMLM_finetuned\\checkpoint-8192\\config.json\n","Model weights saved in RobertaMLM_finetuned\\checkpoint-8192\\pytorch_model.bin\n","Deleting older checkpoint [RobertaMLM_finetuned\\checkpoint-16384] due to args.save_total_limit\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"data":{"text/plain":["TrainOutput(global_step=11880, training_loss=2.560482644232034, metrics={'train_runtime': 1349.3729, 'train_samples_per_second': 563.225, 'train_steps_per_second': 8.804, 'total_flos': 4875959524403712.0, 'train_loss': 2.560482644232034, 'epoch': 20.0})"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"markdown","id":"4f9fe382","metadata":{"id":"4f9fe382"},"source":["#### Check Perplexity score of the model"]},{"cell_type":"code","execution_count":null,"id":"d01728b6","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"elapsed":102518,"status":"ok","timestamp":1670974682488,"user":{"displayName":"francesco sciarra","userId":"17926562299953983564"},"user_tz":-60},"id":"d01728b6","outputId":"b50c5bcc-425b-4d53-8c70-6c3cd33dcc10"},"outputs":[{"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 2455\n","  Batch size = 256\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10/10 00:01]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Perplexity: 9.36\n"]}],"source":["import math\n","eval_results = trainer.evaluate()\n","print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"]},{"cell_type":"markdown","id":"6fed68da","metadata":{"id":"6fed68da"},"source":["### Saving tokenizer & Model to use in Encoder Decoder architecture"]},{"cell_type":"code","execution_count":null,"id":"ba4ad34b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":464,"status":"ok","timestamp":1670974776199,"user":{"displayName":"francesco sciarra","userId":"17926562299953983564"},"user_tz":-60},"id":"ba4ad34b","outputId":"b1ffddd8-4155-408d-da0e-7d29dc9db584"},"outputs":[{"name":"stderr","output_type":"stream","text":["tokenizer config file saved in Byte_tokenizer_finetuned\\tokenizer_config.json\n","Special tokens file saved in Byte_tokenizer_finetuned\\special_tokens_map.json\n"]},{"data":{"text/plain":["('Byte_tokenizer_finetuned\\\\tokenizer_config.json',\n"," 'Byte_tokenizer_finetuned\\\\special_tokens_map.json',\n"," 'Byte_tokenizer_finetuned\\\\vocab.json',\n"," 'Byte_tokenizer_finetuned\\\\merges.txt',\n"," 'Byte_tokenizer_finetuned\\\\added_tokens.json',\n"," 'Byte_tokenizer_finetuned\\\\tokenizer.json')"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.save_pretrained('Byte_tokenizer_finetuned')"]},{"cell_type":"code","execution_count":null,"id":"62f26ed7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1462,"status":"ok","timestamp":1670974779287,"user":{"displayName":"francesco sciarra","userId":"17926562299953983564"},"user_tz":-60},"id":"62f26ed7","outputId":"1f39b4e6-2546-41cb-b3ea-f1c9515997c4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to RobertaMLM_finetuned\n","Configuration saved in RobertaMLM_finetuned\\config.json\n","Model weights saved in RobertaMLM_finetuned\\pytorch_model.bin\n"]}],"source":["trainer.save_model(model_folder)"]},{"cell_type":"markdown","id":"a830a53d","metadata":{"id":"a830a53d"},"source":["# Evaluating Decoder(ROBERTA)"]},{"cell_type":"code","execution_count":null,"id":"aa2efa74","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4439,"status":"ok","timestamp":1670974789702,"user":{"displayName":"francesco sciarra","userId":"17926562299953983564"},"user_tz":-60},"id":"aa2efa74","outputId":"0fd112e6-c600-41d4-f716-92881180c94e"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file RobertaMLM_finetuned\\config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"RobertaMLM_finetuned\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.25.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 10000\n","}\n","\n","loading configuration file RobertaMLM_finetuned\\config.json\n","Model config RobertaConfig {\n","  \"_name_or_path\": \"RobertaMLM_finetuned\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.25.1\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 10000\n","}\n","\n","loading weights file RobertaMLM_finetuned\\pytorch_model.bin\n","All model checkpoint weights were used when initializing RobertaForMaskedLM.\n","\n","All the weights of RobertaForMaskedLM were initialized from the model checkpoint at RobertaMLM_finetuned.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n","loading file vocab.json\n","loading file merges.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n"]}],"source":["from transformers import pipeline\n","\n","fill_mask = pipeline(\n","    \"fill-mask\",\n","    model= r'RobertaMLM_finetuned',\n","    tokenizer= 'Byte_tokenizer_finetuned'\n",")"]},{"cell_type":"code","execution_count":null,"id":"8b3853b8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":293,"status":"ok","timestamp":1670974795749,"user":{"displayName":"francesco sciarra","userId":"17926562299953983564"},"user_tz":-60},"id":"8b3853b8","outputId":"d09395c4-7420-4714-f848-9c1b72d579ff"},"outputs":[{"data":{"text/plain":["[{'score': 0.17281213402748108,\n","  'token': 340,\n","  'token_str': ' white',\n","  'sequence': 'a girl going into a white building'},\n"," {'score': 0.11950363218784332,\n","  'token': 491,\n","  'token_str': ' large',\n","  'sequence': 'a girl going into a large building'},\n"," {'score': 0.09886179864406586,\n","  'token': 377,\n","  'token_str': ' red',\n","  'sequence': 'a girl going into a red building'},\n"," {'score': 0.06501814723014832,\n","  'token': 488,\n","  'token_str': ' yellow',\n","  'sequence': 'a girl going into a yellow building'},\n"," {'score': 0.06376089155673981,\n","  'token': 402,\n","  'token_str': ' blue',\n","  'sequence': 'a girl going into a blue building'}]"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["fill_mask(\"a girl going into a <mask> building\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}